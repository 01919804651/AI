{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanveerCU/AI/blob/master/implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONZ9cBBmP8Vg"
      },
      "source": [
        "# **DRIVE MOUNT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxj29yQMOvKm",
        "outputId": "ad3d7cb3-bd97-4924-f9b2-10113ed98c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from os.path import join\n",
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/drive\"\n",
        "drive.mount(ROOT)\n",
        "\n",
        "PROJ = \"My Drive\" # This is a custom path.\n",
        "PROJECT_PATH = join(ROOT, PROJ)\n",
        "\n",
        "%cd ~\n",
        "%cd /content\n",
        "%cd drive/My Drive/Faster_RCNN_Model_Train_Test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/root\n",
            "/content\n",
            "/content/drive/My Drive/Faster_RCNN_Model_Train_Test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Oh-hZ08K0Yv"
      },
      "source": [
        "# **LOAD DEPENDENCIES + OWN MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl986cIvCyHB",
        "outputId": "556d3639-1254-4ad4-8b96-3813ee068361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.datasets import cifar100\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from skimage.transform import resize\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import cv2 as cv\n",
        "# import the necessary packages\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications import InceptionV3\n",
        "from keras.applications import Xception # TensorFlow ONLY\n",
        "from keras.applications import VGG19\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os, time\n",
        "import matplotlib.pyplot as plt\n",
        "#from keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "#from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16;\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import os\n",
        "import numpy as np\n",
        "from keras import models\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import callbacks\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "np.random.seed(2142)\n",
        "from subprocess import check_output\n",
        "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, Convolution2D, Input,Activation, ZeroPadding2D, MaxPooling2D, Flatten, merge\n",
        "from keras.optimizers import SGD\n",
        "from keras.objectives import sparse_categorical_crossentropy as scc\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56gP_el7K4L_",
        "outputId": "a52244d6-4485-4778-db10-5a03217967a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/FRCNN+OWN_MODEL/lp_CNN_470000_param.h5')\n",
        "model.summary()\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "digit = load_model('/content/drive/My Drive/FRCNN+OWN_MODEL/digit.h5')\n",
        "from tensorflow.keras.models import load_model\n",
        "character = load_model('/content/drive/My Drive/FRCNN+OWN_MODEL/character_ResNet50.h5')\n",
        "#character = load_model('E:/resnet_50/character_ResNet50.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               409856    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 477,994\n",
            "Trainable params: 477,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtMKf2sbVky4",
        "outputId": "b6b226fa-41db-48d5-d1eb-d5a0ae6d379e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd ~\n",
        "%cd /content\n",
        "%cd drive/My Drive/Faster_RCNN_Model_Train_Test/models/research/object_detection/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content\n",
            "/content/drive/My Drive/Faster_RCNN_Model_Train_Test/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi0NYUeWPwVb"
      },
      "source": [
        "# **TEST THE OUTPUT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI-DHFXuPDV6",
        "outputId": "4d9ac81a-158c-4aa4-928f-31f6d997a7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import cv2 as cv\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
        "  raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#from utils import label_map_util\n",
        "\n",
        "#from utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "di={0:\"ko\",1:\"kho\",2:\"go\",3:\"gho\",4:\"cho\",5:\"jo\",6:\"dho\",7:\"lo\",8:\"mo\",9:\"vo\"}\n",
        "\n",
        "\n",
        "\n",
        "def DHAKA_METRO_GO(test_digits):\n",
        "    #test_digits=cv.cvtColor(test_digits, cv.COLOR_BGR2GRAY)\n",
        "    \n",
        "    a=\"NULL\"\n",
        "    \n",
        "    dhaka=[]\n",
        "    go=[]\n",
        "    pic=test_digits\n",
        "    pic=cv.resize(pic,(98,30))\n",
        "    \n",
        "    d=pic[5:25,0:16]\n",
        "    d=cv.resize(d,(32,32))\n",
        "\n",
        "    g=pic[5:25,79:]\n",
        "    g=cv.resize(g,(32,32))\n",
        "    \n",
        "    #print(pic.shape)\n",
        "    #cv.imshow(\"print\",test_digits)\n",
        "    dhaka.append(d)\n",
        "    dhaka=np.array(dhaka)\n",
        "    dhaka = dhaka / 255.0\n",
        "    dhaka = dhaka.reshape(dhaka.shape[0], 32, 32, 3)\n",
        "    dhaka=preprocess_input(dhaka)\n",
        "#    print(test_images.shape)\n",
        "    \n",
        "    dhaka_predict = character.predict(dhaka)\n",
        "    dpoint=(int)(max((dhaka_predict[0])*100.0))\n",
        "    #print(dpoint)\n",
        "    dk=np.argmax(dhaka_predict[0])\n",
        "    \n",
        "    go.append(g)\n",
        "    go = np.array(go)\n",
        "    go = go / 255.0\n",
        "    go = go.reshape(go.shape[0], 32, 32, 3)\n",
        "#    print(test_images.shape)\n",
        "    go=preprocess_input(go)\n",
        "    go_predict = character.predict(go)\n",
        "    gpoint=(int)(max((go_predict[0])*100.0))\n",
        "    #print(gpoint)\n",
        "    gk=np.argmax(go_predict[0])\n",
        "    #classes = character.predict_proba(go)\n",
        "    #print(classes)\n",
        "    #cv.imshow(\"dhaka\",d)\n",
        "    #cv.imshow(\"go\",g)\n",
        "    #print(dk)\n",
        "    #print(gk)\n",
        "    if dk ==6:\n",
        "        a=\"Dhaka Metro \"\n",
        "    if gpoint > 5:\n",
        "        a= a + (str)(di[gk])\n",
        "    \n",
        "    \n",
        " \n",
        "    #dho = d.reshape(1,d.shape[0]*d.shape[1])\n",
        "    #dho = dho/255.0\n",
        "    #dhaka = model.predict(dho)\n",
        "    #print(dhaka)\n",
        "    #print(\" \")\n",
        "    #if dhaka[0] == 16:\n",
        "    #    a=\"DH\"\n",
        "    \n",
        "    \n",
        "    #go = g.reshape(1,g.shape[0]*g.shape[1])\n",
        "    #go = go/255.0\n",
        "    #GO = model.predict(go)\n",
        "    #print(GO)\n",
        "    #print(\" \")\n",
        "    #if GO[0] == 12:\n",
        "    #   a+=\" Go\"\n",
        "    \n",
        "    return (a)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def CNN(test_digits):\n",
        "    test_digits=cv.cvtColor(test_digits, cv.COLOR_BGR2GRAY)\n",
        "    test_images=[]\n",
        "    a=\"\"\n",
        "    pic=test_digits\n",
        "    pic=cv.resize(pic,(28,28))\n",
        "    test_images.append(pic)\n",
        "    test_images=np.array(test_images)\n",
        "    test_images = test_images / 255.0\n",
        "    test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
        "    #print(test_images.shape)\n",
        "    \n",
        "    predictions = digit.predict(test_images)\n",
        "    point=max(predictions[0])\n",
        "    #print(point)\n",
        "    a=np.argmax(predictions[0])\n",
        "    #print(a)\n",
        "    \n",
        "    \n",
        "    #a=\"\"\n",
        "    #img=cv.cvtColor(test_digits, cv.COLOR_BGR2GRAY)\n",
        "    #img=cv.resize(img,(32,32))\n",
        "    #x_test_flatten = img.reshape(1,img.shape[0]*img.shape[1])\n",
        "    #x_test_flatten = x_test_flatten/255.0\n",
        "    #p = dm.predict(x_test_flatten)\n",
        "    #k=0\n",
        "    #for i in p:\n",
        "    #    k=i\n",
        "    #a=(str)(k)\n",
        "    #print(a)\n",
        "    #print(\" \")\n",
        "    \n",
        "    return(a)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# What model to download.\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/content/drive/My Drive/FRCNN+OWN_MODEL' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('/content/drive/My Drive/FRCNN+OWN_MODEL/', 'label_map.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "       \n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/drive/My Drive/FRCNN+OWN_MODEL/'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'i{}.jpg'.format(i)) for i in range(1, 5) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cnt=0\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    cnt+=1\n",
        "    user=\"Car \"+(str)(cnt)\n",
        "    target_image = Image.open(image_path)\n",
        "    image_np = load_image_into_numpy_array(target_image)\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "#    print(output_dict['detection_classes'][0])\n",
        "#    print(output_dict['detection_boxes'][0])\n",
        "    (im_width, im_height) = target_image.size\n",
        "    ymin = output_dict['detection_boxes'][0,0]\n",
        "    xmin = output_dict['detection_boxes'][0,1]\n",
        "    ymax = output_dict['detection_boxes'][0,2]\n",
        "    xmax = output_dict['detection_boxes'][0,3]\n",
        "    (xminn, xmaxx, yminn, ymaxx) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
        "#    print(xminn,\" \", xmaxx, \" \",yminn, \" \",ymaxx)\n",
        "    plate=image_np[(int)(yminn):(int)(ymaxx),(int)(xminn):(int)(xmaxx)]\n",
        "\n",
        "    img=plate\n",
        "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "    img=cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "    image = cv.adaptiveThreshold(gray,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,11,2)\n",
        "    image=cv.resize(image,(141,73))\n",
        "    img=cv.resize(img,(141,73))\n",
        "\n",
        "    left=0\n",
        "    right=0\n",
        "    up=0\n",
        "    down=0\n",
        "    i=0\n",
        "    j=1    \n",
        "    \n",
        "    im=image[0:73,0:141]\n",
        "    while(i<20):\n",
        "        image[0:73,i:j] ##left\n",
        "        image[i:j,0:141]## up\n",
        "        image[0:73,141-j:141-i]##right\n",
        "        image[73-j:73-i,0:141]##down\n",
        "        i+=1\n",
        "        j+=1\n",
        "        l=1\n",
        "        left_zero=0\n",
        "        right_zero=0\n",
        "        for k in range(73):\n",
        "            left_margin=image[k:l,i:j]\n",
        "            right_margin=image[k:l,141-j:141-i]\n",
        "            l+=1\n",
        "            if left_margin==0:\n",
        "                left_zero+=1\n",
        "            if left_zero>58:\n",
        "                left=i+3\n",
        "                left_zero=0\n",
        "            if right_margin==0:\n",
        "                right_zero+=1\n",
        "            if right_zero>58:\n",
        "                right=(141-i)-2\n",
        "                right_zero=0    \n",
        "        n=1\n",
        "        up_zero=0\n",
        "        down_zero=0\n",
        "        for m in range(141):\n",
        "            up_margin=image[i:j,m:n]## up\n",
        "            down_margin=image[73-j:73-i,m:n]##down\n",
        "            n+=1\n",
        "            if up_margin==0:\n",
        "                up_zero+=1\n",
        "            if down_margin==0:\n",
        "                down_zero+=1\n",
        "            if up_zero>112:\n",
        "                up=i+5\n",
        "                up_zero=0\n",
        "            if down_zero>112:\n",
        "                down=(73-j)-2\n",
        "                down_zero=0  \n",
        "    \n",
        "#    print(up,\" \",down,\" \",left,\" \",right)\n",
        "    if down==0:\n",
        "        down=73-3\n",
        "    if right==0:\n",
        "        right=141-3\n",
        "    image=image[up:down,left:right]\n",
        "    img=img[up:down,left:right]\n",
        "    img=cv.resize(img,(141,73))\n",
        "    img=cv.cvtColor(img, cv.COLOR_GRAY2BGR)  \n",
        "    \n",
        "    g=image.shape\n",
        "    c=img.shape\n",
        "#    print(g)\n",
        "#    print(c)  \n",
        "#    cv.imshow(\"modify\",image)\n",
        "#    cv.imshow(\"good\",im)\n",
        "#    cv.imshow(\"colored\",img)\n",
        "    \n",
        "    row_half=(int)(c[0]/2)    \n",
        "    \n",
        "    segment=img[row_half+5:,:]\n",
        "#    cv.imshow(\"segment\",segment)\n",
        "\n",
        "    \n",
        "    dhaka_segment=img[9:row_half+5,5:55]\n",
        "#    cv.imshow(\"dhaka\",dhaka_segment)\n",
        "\n",
        "    metro_segment=img[9:row_half+5,57:110]\n",
        "#    cv.imshow(\"metro\",metro_segment)\n",
        "    \n",
        "    go_segment=img[9:row_half+5,113:]\n",
        "#    cv.imshow(\"go\",go_segment)\n",
        "    \n",
        "   \n",
        "    \n",
        "    \n",
        "    one_1=segment[:,:20]\n",
        "    one_2=segment[:,:25]\n",
        "    \n",
        "   \n",
        "    \n",
        "    two_1=segment[:,20:20+20]\n",
        "    two_2=segment[:,20:20+25]\n",
        "\n",
        "    \n",
        "    \n",
        "    three_1=segment[:,57:57+20]\n",
        "    three_2=segment[:,57:57+25]\n",
        "\n",
        "    \n",
        "    four_1=segment[:,57+20:57+20+20]\n",
        "    four_2=segment[:,57+20:57+20+25]\n",
        "\n",
        "    \n",
        "    five_1=segment[:,57+20+20:57+20+20+20]\n",
        "    five_2=segment[:,57+20+20:57+20+20+25]\n",
        "\n",
        "    \n",
        "    six_1=segment[:,57+20+20+20:]\n",
        "\n",
        "    \n",
        "    \n",
        "    #on_1=CNN(one_1)\n",
        "    on_2=CNN(one_2)\n",
        "    #tw_1=CNN(two_1)\n",
        "    tw_2=CNN(two_2)\n",
        "    #th_1=CNN(three_1)\n",
        "    th_2=CNN(three_2)\n",
        "    #fr_1=CNN(four_1)\n",
        "    fr_2=CNN(four_2)\n",
        "    #fv_1=CNN(five_1)\n",
        "    fv_2=CNN(five_2)\n",
        "    sx_1=CNN(six_1)\n",
        "    #dhaka=GO_DHAKA(dhaka_segment)\n",
        "\n",
        "#    metro=KNN(metro_segment)\n",
        "\n",
        "    #go=GO_DHAKA(go_segment)\n",
        "\n",
        "    \n",
        "    \n",
        "#    print(on_1)\n",
        "#    print(on_2)\n",
        "#    print(tw_1)\n",
        "#    print(tw_2)\n",
        "#    print(th_1)\n",
        "#    print(th_2)\n",
        "#    print(fr_1)\n",
        "#    print(fr_2)\n",
        "#    print(fv_1)\n",
        "#    print(fv_2)\n",
        "#    print(sx_1)\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "    image_np=cv.cvtColor(image_np, cv.COLOR_BGR2RGB)  \n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=2)    \n",
        "    \n",
        "    \n",
        "\n",
        "      \n",
        "    picture=cv.imread('/content/drive/My Drive/FRCNN+OWN_MODEL/frame.jpg')\n",
        "  #    frame=cv.imread('project1.jpg')\n",
        "  #    frame=cv.resize(frame,(416,416))\n",
        "    picture=cv.resize(picture,(560,488))\n",
        "    image_np=cv.resize(image_np,(416,416))\n",
        "    picture[23:23+416,1:1+416]=image_np\n",
        "      \n",
        "    im=cv.cvtColor(im, cv.COLOR_GRAY2BGR) \n",
        "    im=cv.resize(im,(137,47))\n",
        "    picture[23:23+47,419:419+137]=im\n",
        "      \n",
        "      \n",
        "    image=cv.cvtColor(image, cv.COLOR_GRAY2BGR) \n",
        "    image=cv.resize(image,(137,47))\n",
        "    picture[98:145,419:419+137]=image\n",
        "      \n",
        "      \n",
        "      \n",
        "    segment0=img[9:row_half+5,:]\n",
        "    segment0=cv.resize(segment0,(137,25))\n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "    img=cv.resize(img,(137,47))\n",
        "    picture[173:220,419:419+137]=img\n",
        "      \n",
        "      \n",
        "      \n",
        "\n",
        "      #cv.imshow('segment0',segment0)\n",
        "    picture[248:273,419:419+137]=segment0\n",
        "      \n",
        "      \n",
        "      \n",
        "    dhaka_segment=cv.resize(dhaka_segment,(40,27))\n",
        "    picture[345:345+27,419:419+40]=dhaka_segment\n",
        "      \n",
        "    metro_segment = cv.resize(metro_segment,(40,27))\n",
        "    picture[345:345+27,474:514]= metro_segment\n",
        "      \n",
        "    go_segment = cv.resize(go_segment,(25,27))\n",
        "    picture[345:345+27,530:555]= go_segment  \n",
        "      \n",
        "      \n",
        "    segment=cv.resize(segment,(137,25))\n",
        "    picture[297:322,419:419+137]=segment\n",
        "      \n",
        "      \n",
        "    one_2=cv.resize(one_2,(30,25))\n",
        "    picture[398:398+25,419:419+30]=one_2\n",
        "      \n",
        "    two_2=cv.resize(two_2,(30,25))\n",
        "    picture[398:398+25,471:471+30]=two_2\n",
        "      \n",
        "      \n",
        "    three_2=cv.resize(three_2,(30,25))\n",
        "    picture[398:398+25,525:525+30]=three_2\n",
        "      \n",
        "      \n",
        "    four_2=cv.resize(four_2,(30,25))\n",
        "    picture[458:458+25,419+3:419+30+3]=four_2\n",
        "      \n",
        "    five_2=cv.resize(five_2,(30,25))\n",
        "    picture[458:458+25,471:471+30]=five_2\n",
        "      \n",
        "    six_1=cv.resize(six_1,(30,25))\n",
        "    picture[458:458+25,525:525+30]=six_1\n",
        "    dmg=DHAKA_METRO_GO(segment0)\n",
        "      #dmg=test(segment0)\n",
        "      \n",
        "      \n",
        "      \n",
        "      # font \n",
        "    font = cv.FONT_HERSHEY_SIMPLEX \n",
        "\n",
        "      # org \n",
        "    org = (115, 475) \n",
        "\n",
        "      # fontScale \n",
        "    fontScale = 1\n",
        "\n",
        "      # Blue color in BGR \n",
        "    color = (0, 0, 0) \n",
        "\n",
        "      # Line thickness of 2 px \n",
        "    thickness = 2\n",
        "\n",
        "      # Using cv2.putText() method \n",
        "    one=(int)(on_2)\n",
        "    two=(int)(tw_2)\n",
        "    three=(int)(th_2)\n",
        "    four=(int)(fr_2)\n",
        "    five=(int)(fv_2)\n",
        "    six=(int)(sx_1)\n",
        "    dhaka_org=(121, 475) \n",
        "    num_org=(279, 475) \n",
        "        \n",
        "        \n",
        "    text=(str)(one)+(str)(two)+(str)(three)+(str)(four)+(str)(five)+(str)(six)\n",
        "    print(dmg)\n",
        "    print(text)\n",
        "        \n",
        "    picture = cv.putText(picture, dmg , dhaka_org, font,  \n",
        "                    fontScale, color, thickness, cv.LINE_AA)\n",
        "            \n",
        "    picture = cv.putText(picture, text , num_org, font,  \n",
        "                    fontScale, color, thickness, cv.LINE_AA)\n",
        "      \n",
        "      #cv.imshow(\"window\",picture)\n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "\n",
        "  #    window=\"window\"+(str)(cnt)\n",
        "  #    licence=\"licence\"+(str)(cnt)\n",
        "      #cv.imshow(\"window\",picture)\n",
        "      \n",
        "  #################################################################################\n",
        "    image_np=cv.resize(image_np,(608,608))\n",
        "    image_np=cv.cvtColor(image_np, cv.COLOR_BGR2RGB)\n",
        "    picture=cv.cvtColor(picture, cv.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    #plt.imshow(image_np)\n",
        "    with open('/content/drive/My Drive/Final_project_implementation/data.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([user, dmg, text])\n",
        "    \n",
        "  #################################################################################    \n",
        "\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dhaka Metro go\n",
            "423018\n",
            "Dhaka Metro go\n",
            "156586\n",
            "Dhaka Metro go\n",
            "423018\n",
            "Dhaka Metro go\n",
            "276080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxr2HzLOdMnH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}